from pyflink.datastream import StreamExecutionEnvironment
from pyflink.table import StreamTableEnvironment

# ì‹¤í–‰ í™˜ê²½ ì„¤ì •
env = StreamExecutionEnvironment.get_execution_environment()
t_env = StreamTableEnvironment.create(env)

# âœ… JAR íŒŒì¼ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
t_env.get_config().get_configuration().set_string(
    "pipeline.jars",
"file:///Users/hangyeongmin/Downloads/flink-connector-kafka-3.4.0-1.20.jar"
)

# âœ… Kafka ì†ŒìŠ¤ í…Œì´ë¸” ìƒì„±
t_env.execute_sql("""
    CREATE TABLE kafka_source (
        Movie_Name STRING,
        Similarity_weight INT,
        top_n INT
    ) WITH (
        'connector' = 'kafka',
        'topic' = 'test-topic',
        'properties.bootstrap.servers' = 'localhost:29092',
        'format' = 'json',
        'scan.startup.mode' = 'earliest-offset'
    )
""")

# âœ… Kafkaì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” SQL ì‹¤í–‰
result_table = t_env.sql_query("SELECT * FROM kafka_source")

# âœ… ì‹¤í–‰ í™˜ê²½ì—ì„œ ë³€í™˜í•˜ì—¬ ë°ì´í„° ì¶œë ¥
result_stream = t_env.to_data_stream(result_table)

# âœ… ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def print_result(record):
    print(f"ğŸ“© Kafka Message: {record}")

# âœ… ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ì¶œë ¥
result_stream.map(print_result)

# âœ… ì‹¤í–‰ ì‹œì‘
env.execute("Kafka Flink Consumer")

